{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LucilleKaleha_UPDATED__Womxn_in_Big_Data_South_Africa_2nd_position___Solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucilleKaleha/Second-position-solution-for-the-Womxn-in-Big-Data-South-Africa-competition/blob/master/LucilleKaleha_UPDATED__Womxn_in_Big_Data_South_Africa_2nd_position___Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEGztEl3U2P5",
        "colab_type": "text"
      },
      "source": [
        "## [Lucille Kaleha ](https://www.linkedin.com/in/lucillekaleha/): **Second position solution for the Womxn in Big Data South Africa competition**\n",
        "\n",
        "\n",
        "---\n",
        "*Thanks to Zindi, Women in Big Data, HERE Technologies and Microsoft for this challenge and opportunity to improve livelihoods using Data Science*\n",
        "\n",
        "### Challenges faced:\n",
        " - Feature engineering did not yield good results\n",
        " - There was no correlation between local cross validation and the leaderbaord, so it was challenging to know how good a model is and whether it was overfitting\n",
        " - Using all the data for training yielded worse results\n",
        " - It was very challenging to get new data from the recommended HERE and XYZ apis.\n",
        " \n",
        "### Approach used:\n",
        " - Focused more on bulding models rather than feature engineering\n",
        " - As location was an important feature, i reverse geocoded the coordinates to get locations for each latitude and longitude using the reversegeocoding python library\n",
        " - As there was no single model that yielded good results, i opted to train several models so that they can cancel each others errors and generalize well\n",
        " - Because using all the data yielded unsatisfactory resultes, i opted to train each model with 70% of the data\n",
        " - To ensure that all the data has been used for training, i used different random states to split the data\n",
        " - Finally to generalise the ensembled models; I averaged, blended and retrained the models using the test data as training data and predictions as the target\n",
        " \n",
        "### Some small caveats:\n",
        " - I realised that using different versions of catboost regressor yielded different results, so i maximised on this and used two versions of catboost.\n",
        "    - At some point in the notebook you will have to restart the kernel.\n",
        " - Setting the random states(seed) did help for reproducability, but some models dont have the random state parameter, so there is some bias/randomness that cannot be accounted for. So predictions will differ by a small margin whenever you run the notebook.\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqAO45Wq7Y_g",
        "colab_type": "code",
        "outputId": "7776b683-e96f-4636-ac28-ebe7e592c0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        }
      },
      "source": [
        "# Installing the necessary libraries\n",
        "#\n",
        "!pip install vecstack                   # For stacking models\n",
        "!pip install catboost==0.20.2           # This version of catboost yielded better results with certain random states\n",
        "!pip install reverse_geocoder           # Used to get location of a place, given coordinates"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vecstack\n",
            "  Downloading https://files.pythonhosted.org/packages/d0/a1/b9a1e9e9e5a12078da1ab9788c7885e4c745358f7e57d5f94d9db6a4e898/vecstack-0.4.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.18.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from vecstack) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from vecstack) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->vecstack) (0.14.1)\n",
            "Building wheels for collected packages: vecstack\n",
            "  Building wheel for vecstack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vecstack: filename=vecstack-0.4.0-cp36-none-any.whl size=19877 sha256=286796dcf1e6e5c7975e12f274feb6d26eacdc04a45749ac12a2426cd1c473f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/bb/4e/f6488433d53bc0684673d6845e5bf11a25240577c8151c140e\n",
            "Successfully built vecstack\n",
            "Installing collected packages: vecstack\n",
            "Successfully installed vecstack-0.4.0\n",
            "Collecting catboost==0.20.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/c4/586923de4634f88a31fd1b4966e15707a912b98b6f4566651b5ef58f36b5/catboost-0.20.2-cp36-none-manylinux1_x86_64.whl (63.9MB)\n",
            "\u001b[K     |████████████████████████████████| 63.9MB 51kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost==0.20.2) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost==0.20.2) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost==0.20.2) (1.18.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost==0.20.2) (0.25.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost==0.20.2) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost==0.20.2) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost==0.20.2) (1.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost==0.20.2) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost==0.20.2) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost==0.20.2) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost==0.20.2) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost==0.20.2) (2.4.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost==0.20.2) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost==0.20.2) (45.2.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.20.2\n",
            "Collecting reverse_geocoder\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/0f/b7d5d4b36553731f11983e19e1813a1059ad0732c5162c01b3220c927d31/reverse_geocoder-1.5.1.tar.gz (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from reverse_geocoder) (1.18.1)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from reverse_geocoder) (1.4.1)\n",
            "Building wheels for collected packages: reverse-geocoder\n",
            "  Building wheel for reverse-geocoder (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for reverse-geocoder: filename=reverse_geocoder-1.5.1-cp36-none-any.whl size=2268091 sha256=5eef3a8d5ebbdf7cc99c009487856d376b299a19372678caba82fcab1f937283\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/05/50/b1350ff094ef91e082665b4a2f9ca551f8acea4aa55d796b26\n",
            "Successfully built reverse-geocoder\n",
            "Installing collected packages: reverse-geocoder\n",
            "Successfully installed reverse-geocoder-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67UJh-5jkRL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the necessary libraries\n",
        "#\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import StringIO \n",
        "import reverse_geocoder as rg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR, NuSVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor, XGBRFRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor,HistGradientBoostingRegressor, ExtraTreesRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from lightgbm import LGBMRegressor\n",
        "from vecstack import stacking\n",
        "from vecstack import StackingTransformer\n",
        "from catboost import CatBoostRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOSZr0a113UC",
        "colab_type": "text"
      },
      "source": [
        "### Loading and cleaning data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRMvzJcBfUKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Created links to shared files via google drive\n",
        "#\n",
        "train = 'https://drive.google.com/file/d/13GpeDjiVR1aRHpkAZc7EeH_cKf52q7qE/view?usp=sharing'\n",
        "test = 'https://drive.google.com/file/d/17JoUvCmpFXXFbgbZ9Ki3Xqh9qcl7UV8c/view?usp=sharing'\n",
        "submission = 'https://drive.google.com/file/d/1GN1lSsLU43kQaZtThc4dP60mz8ztwDsL/view?usp=sharing'\n",
        "dictionary = 'https://drive.google.com/file/d/1lAZnQFsBkPo8TNHYbq5mt2SpSMrG57WR/view?usp=sharing'\n",
        "\n",
        "\n",
        "# Created a function to read a csv file shared via google and return a dataframe\n",
        "#\n",
        "def read_csv(url):\n",
        "  url = 'https://drive.google.com/uc?export=download&id=' + url.split('/')[-2]\n",
        "  csv_raw = requests.get(url).text\n",
        "  csv = StringIO(csv_raw)\n",
        "  df = pd.read_csv(csv)\n",
        "  return df\n",
        "\n",
        "# Creating submission, training, testing and variable definition datataframes\n",
        "#\n",
        "sub = read_csv(submission)\n",
        "train = read_csv(train)\n",
        "test = read_csv(test)\n",
        "submission = read_csv(submission)\n",
        "dictionary = read_csv(dictionary)\n",
        "\n",
        "# Splitting the target variable from the train dataframe\n",
        "#\n",
        "target = train.target\n",
        "\n",
        "\n",
        "# Aligning the training and testing datasets\n",
        "train, test = train.align(test, join = 'inner', axis = 1)\n",
        "\n",
        "\n",
        "# Including a separator column to be used to split the dataframes after combining them\n",
        "#\n",
        "train['separator'] = 0\n",
        "test['separator'] = 1\n",
        "\n",
        "\n",
        "# Combining the test and train dataframes, so that feature engineering can be done on the go\n",
        "#\n",
        "comb = pd.concat([train, test])\n",
        "\n",
        "# Separating the training and testing dataframes from the combined dataframe\n",
        "#\n",
        "train = comb[comb.separator == 0]\n",
        "test = comb[comb.separator == 1]\n",
        "\n",
        "\n",
        "# Dropping the separator column as it has served its purpose\n",
        "#\n",
        "train.drop('separator', axis = 1, inplace = True)\n",
        "test.drop('separator', axis = 1, inplace = True)\n",
        "train['target'] = target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQFw7hoL18qU",
        "colab_type": "text"
      },
      "source": [
        "### Catboost Predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-QpiT7rlX49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the data into training and testing dataframes\n",
        "#\n",
        "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)  # Predictors\n",
        "y = target                                                  # Target\n",
        "\n",
        "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)           # Testing data\n",
        "\n",
        "# Splitting the training dataset to 70%, and setting the random state to 90\n",
        "#\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 90)\n",
        "\n",
        "# Making predictions\n",
        "#\n",
        "predictions_cat = CatBoostRegressor(logging_level='Silent').fit(X_train, y_train).predict(tes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph8CUGE92Kmp",
        "colab_type": "text"
      },
      "source": [
        "### Sklearn Stacking Regressor Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9aXdPYEe-YK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using two different stacked ensembles to make predictions using the sklearn stacking regressor\n",
        "#\n",
        "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
        "y = target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 90)\n",
        "\n",
        "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
        "\n",
        "estimators_1 = [\n",
        "    ('xgb', XGBRegressor(objective ='reg:squarederror')),\n",
        "    ('lr', LinearRegression()),\n",
        "    ('rf', RandomForestRegressor()),\n",
        "    ('lgb', LGBMRegressor()),\n",
        "    ('svr', SVR()),\n",
        "    ('lasso', Lasso()),\n",
        "    ('kneiba', KNeighborsRegressor()),\n",
        "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
        "]\n",
        "\n",
        "predictions_sreg = StackingRegressor(estimators=estimators_1, final_estimator=CatBoostRegressor(logging_level='Silent')).fit(X_train, y_train).predict(tes)\n",
        "\n",
        "\n",
        "estimators_2 = [\n",
        "    ('XBRF', XGBRFRegressor(objective ='reg:squarederror')),\n",
        "    ('Bayesian', BayesianRidge()),\n",
        "    ('ExtraTrees', ExtraTreesRegressor()),\n",
        "    ('HistGradient', HistGradientBoostingRegressor()),\n",
        "    ('NuSVR', NuSVR()),\n",
        "    ('Ridge', Ridge()),\n",
        "    ('KNeiba', KNeighborsRegressor()),\n",
        "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
        "]\n",
        "\n",
        "predictions_sreg_2 = StackingRegressor(estimators=estimators_2, final_estimator=CatBoostRegressor(logging_level='Silent')).fit(X_train, y_train).predict(tes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUYyZQn82PZF",
        "colab_type": "text"
      },
      "source": [
        "### Vecstack Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L74m8Rx1e-VN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using two different stacked ensembles to make predictions using the vecstack stacking regressor\n",
        "#\n",
        "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
        "y = target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 90)\n",
        "\n",
        "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
        "\n",
        "estimators_1 = [\n",
        "    ('xgb', XGBRegressor(objective ='reg:squarederror')),\n",
        "    ('lr', LinearRegression()),\n",
        "    ('rf', RandomForestRegressor()),\n",
        "    ('lgb', LGBMRegressor()),\n",
        "    ('svr', SVR()),\n",
        "    ('lasso', Lasso()),\n",
        "    ('kneiba', KNeighborsRegressor()),\n",
        "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
        "]\n",
        "\n",
        "stack = StackingTransformer(estimators_1, regression=True, verbose=0, metric =mean_squared_error, shuffle=True)\n",
        "stack = stack.fit(X_train, y_train)\n",
        "S_train = stack.transform(X_train)\n",
        "\n",
        "\n",
        "final_estimator = CatBoostRegressor(logging_level='Silent')\n",
        "final_estimator = final_estimator.fit(S_train, y_train)\n",
        "\n",
        "S_tes = stack.transform(tes)\n",
        "predictions_vecstack = final_estimator.predict(S_tes)\n",
        "\n",
        "\n",
        "\n",
        "estimators_2 = [\n",
        "    ('XBRF', XGBRFRegressor(objective ='reg:squarederror')),\n",
        "    ('Bayesian', BayesianRidge()),\n",
        "    ('ExtraTrees', ExtraTreesRegressor()),\n",
        "    ('HistGradient', HistGradientBoostingRegressor()),\n",
        "    ('NuSVR', NuSVR()),\n",
        "    ('Ridge', Ridge()),\n",
        "    ('KNeiba', KNeighborsRegressor()),\n",
        "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
        "]\n",
        "\n",
        "stack = StackingTransformer(estimators_2, regression=True, verbose=0, metric =mean_squared_error, shuffle=True)\n",
        "stack = stack.fit(X_train, y_train)\n",
        "S_train = stack.transform(X_train)\n",
        "\n",
        "\n",
        "final_estimator = CatBoostRegressor(logging_level='Silent')\n",
        "final_estimator = final_estimator.fit(S_train, y_train)\n",
        "\n",
        "S_tes = stack.transform(tes)\n",
        "predictions_vecstack_2 = final_estimator.predict(S_tes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Est6Jhsi6Oa",
        "colab_type": "text"
      },
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNKqShSb_agx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Created links to shared files via google drive\n",
        "#\n",
        "train = 'https://drive.google.com/file/d/13GpeDjiVR1aRHpkAZc7EeH_cKf52q7qE/view?usp=sharing'\n",
        "test = 'https://drive.google.com/file/d/17JoUvCmpFXXFbgbZ9Ki3Xqh9qcl7UV8c/view?usp=sharing'\n",
        "submission = 'https://drive.google.com/file/d/1GN1lSsLU43kQaZtThc4dP60mz8ztwDsL/view?usp=sharing'\n",
        "dictionary = 'https://drive.google.com/file/d/1lAZnQFsBkPo8TNHYbq5mt2SpSMrG57WR/view?usp=sharing'\n",
        "\n",
        "\n",
        "# Created a function to read a csv file shared via google and return a dataframe\n",
        "#\n",
        "def read_csv(url):\n",
        "  url = 'https://drive.google.com/uc?export=download&id=' + url.split('/')[-2]\n",
        "  csv_raw = requests.get(url).text\n",
        "  csv = StringIO(csv_raw)\n",
        "  df = pd.read_csv(csv)\n",
        "  return df\n",
        "\n",
        "# Creating submission, training, testing and variable definition datataframes\n",
        "#\n",
        "sub = read_csv(submission)\n",
        "train = read_csv(train)\n",
        "test = read_csv(test)\n",
        "submission = read_csv(submission)\n",
        "dictionary = read_csv(dictionary)\n",
        "\n",
        "# Splitting the target variable from the train dataframe\n",
        "#\n",
        "target = train.target\n",
        "\n",
        "\n",
        "# Aligning the training and testing datasets\n",
        "train, test = train.align(test, join = 'inner', axis = 1)\n",
        "\n",
        "\n",
        "# Including a separator column to be used to split the dataframes after combining them\n",
        "#\n",
        "train['separator'] = 0\n",
        "test['separator'] = 1\n",
        "\n",
        "\n",
        "# Combining the test and train dataframes, so that feature engineering can be done on the go\n",
        "#\n",
        "comb = pd.concat([train, test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WHQcFpI_aWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Reverse geocoding coordinates to locations\n",
        "# #\n",
        "# name = []\n",
        "\n",
        "# for i in range(len(comb)):\n",
        "#   location = rg.search([(x, y) for x, y in zip(comb.lat, comb.lon)][i])\n",
        "#   name.append(location[0].get('name'))\n",
        "\n",
        "\n",
        "# # Adding the geocoded locations to the combined dataframe\n",
        "# comb['name'] = name\n",
        "\n",
        "# # Creating a csv file of the combined dataframe\n",
        "# comb.to_csv('women_comb.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26jJrCIJhd0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the combined created csv\n",
        "#\n",
        "def read_csv(url):\n",
        "  url = 'https://drive.google.com/uc?export=download&id=' + url.split('/')[-2]\n",
        "  csv_raw = requests.get(url).text\n",
        "  csv = StringIO(csv_raw)\n",
        "  return csv\n",
        "\n",
        "comb_link = 'https://drive.google.com/file/d/1lglzdXOnAlQntIYK-RdYJv8DtckV6xtm/view?usp=sharing'\n",
        "comb = pd.read_csv(read_csv(comb_link), index_col = 0)\n",
        "comb.drop(['admin1',\t'admin2'], axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "# Creating a column of how many time a location is represented in the dataset\n",
        "#\n",
        "freq_cols = ['name']\n",
        "for col in freq_cols:\n",
        "  fq_encode = comb[col].value_counts().to_dict()\n",
        "  comb[col+'_fq_enc'] = comb[col].map(fq_encode)\n",
        "\n",
        "# One hot encoding the location column\n",
        "#\n",
        "comb = pd.get_dummies(comb, columns = ['name'], drop_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFvrcOJRo024",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generating more features\n",
        "#\n",
        "comb['Household_Size'] = comb['total_individuals']/comb['total_households']\n",
        "comb['psa_car1_car_2'] = comb.psa_00/(comb.car_00 + comb.car_01)\n",
        "comb['latlon'] = abs(comb.lat) + abs(comb.lon)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwUa1wWbktmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separating the train and test dataframes from the combined dataframe\n",
        "#\n",
        "train = comb[comb.separator == 0]\n",
        "test = comb[comb.separator == 1]\n",
        "\n",
        "train.drop('separator', axis = 1, inplace = True)\n",
        "test.drop('separator', axis = 1, inplace = True)\n",
        "train['target'] = target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eee1e4hktft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the data with the new features and making predictions\n",
        "#\n",
        "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
        "y = target\n",
        "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
        "\n",
        "predictions_feats = CatBoostRegressor(logging_level='Silent', random_state=101).fit(X, y).predict(tes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcm5vTJO1Kpb",
        "colab_type": "text"
      },
      "source": [
        "### Averaging, Blending and Retraining"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPTGn86mktdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Averaging the two stacked predictions from sklearn and vecstack in the ratio of 9:1\n",
        "#\n",
        "predictions_vecstack = [x*0.9 + y*0.1 for x, y in zip(predictions_vecstack, predictions_vecstack_2)]\n",
        "predictions_sreg = [x*0.9 + y*0.1 for x, y in zip(predictions_sreg, predictions_sreg_2)]\n",
        "\n",
        "\n",
        "# Blending the two ensemble models and the catboost single model\n",
        "#\n",
        "stack = [x*0.3 + y*0.7 for x, y in zip(predictions_vecstack, predictions_sreg)]\n",
        "stack_2 = [x*0.9 + y*0.1 for x, y in zip(stack, predictions_cat)]\n",
        "stack_3 = [x*0.7 + y*0.3 for x, y in zip(stack_2, predictions_feats)]\n",
        "\n",
        "\n",
        "# Retraining the models using the test data as training data and the predictions as the target\n",
        "#\n",
        "X = tes.copy()\n",
        "y = stack_3\n",
        "\n",
        "ridge = Ridge()\n",
        "ridge.fit(X, y)\n",
        "preds_ridge = ridge.predict(X)\n",
        "\n",
        "cat = CatBoostRegressor(verbose = False)\n",
        "cat.fit(X, y)\n",
        "preds_cat = cat.predict(X)\n",
        "# Blending the two trained models\n",
        "#\n",
        "blended_1 = [x*0.5 +y*0.5 for x, y in zip(preds_ridge, preds_cat)]\n",
        "\n",
        "\n",
        "\n",
        "# Retrainig the models using the above approach but using different weights\n",
        "#\n",
        "stack = [x*0.4 + y*0.6 for x, y in zip(predictions_vecstack, predictions_sreg)]\n",
        "stack_2 = [x*0.8 + y*0.2 for x, y in zip(stack, predictions_cat)]\n",
        "stack_3 = [x*0.65 + y*0.35 for x, y in zip(stack_2, predictions_feats)]\n",
        "\n",
        "X = tes.copy()\n",
        "y = stack_3\n",
        "\n",
        "ridge = Ridge()\n",
        "ridge.fit(X, y)\n",
        "preds_ridge = ridge.predict(X)\n",
        "\n",
        "cat = CatBoostRegressor(verbose = False)\n",
        "cat.fit(X, y)\n",
        "preds_cat = cat.predict(X)\n",
        "\n",
        "blended_2 = [x*0.5 +y*0.5 for x, y in zip(preds_ridge, preds_cat)]\n",
        "\n",
        "blended_3 = [x*0.9 + y*0.1 for x, y in zip(blended_1, blended_2)]\n",
        "\n",
        "\n",
        "# Further generalising the model by training using the simple Linear regression model\n",
        "# Complementing it with the catboost model\n",
        "#\n",
        "X = tes.copy()\n",
        "y = blended_3\n",
        "\n",
        "linear = LinearRegression()\n",
        "linear.fit(X, y)\n",
        "preds_linear = linear.predict(X)\n",
        "\n",
        "cat = CatBoostRegressor(verbose = False)\n",
        "cat.fit(X, y)\n",
        "preds_cat = cat.predict(X)\n",
        "\n",
        "\n",
        "# Blending the two model predictions\n",
        "# Creating a predictions file to be used in the next step, as you will have to restart the kernel\n",
        "#\n",
        "final_blend_1 = [x*0.1 + y*0.1 + z*0.8 for x, y, z in zip(preds_linear, preds_cat, blended_3)]\n",
        "sub_df = pd.DataFrame({'ward': test.ward, 'target': final_blend_1}) \n",
        "sub_df.to_csv('final_blend_1.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5AZ9X5z3VPT",
        "colab_type": "text"
      },
      "source": [
        "### More Ensembles for further regularisation\n",
        "### Train using latest version of catboost\n",
        "### **Restart kernel after installing the latest version of catboost**\n",
        "### *Run the notebook from the cell below after upgrading catboost*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9CsLMVFktT7",
        "colab_type": "code",
        "outputId": "10523b86-db01-47f0-ca05-d86978eee1dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        }
      },
      "source": [
        "# Restart kernel after upgrading catboost and run notebook from this cell\n",
        "!pip install catboost --upgrade"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/ec/12b9a42b2ea7dfe5b602f235692ab2b61ee1334ff34334a15902272869e8/catboost-0.22-cp36-none-manylinux1_x86_64.whl (64.4MB)\n",
            "\u001b[K     |████████████████████████████████| 64.4MB 45kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.18.1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (0.25.3)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.6)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (45.2.0)\n",
            "Installing collected packages: catboost\n",
            "  Found existing installation: catboost 0.20.2\n",
            "    Uninstalling catboost-0.20.2:\n",
            "      Successfully uninstalled catboost-0.20.2\n",
            "Successfully installed catboost-0.22\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "catboost"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJUBIGdTl_HE",
        "colab_type": "code",
        "outputId": "6e059efe-9c63-4c38-9a10-796738efcea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "Restart kernel, and run from below"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-e131013b9632>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Restart kernel, and run from below\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44p4hbTp4_NQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing the necessary libraries\n",
        "#\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import StringIO \n",
        "import reverse_geocoder as rg\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVR, NuSVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor, XGBRFRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor,HistGradientBoostingRegressor, ExtraTreesRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from lightgbm import LGBMRegressor\n",
        "from vecstack import stacking\n",
        "from vecstack import StackingTransformer\n",
        "from catboost import CatBoostRegressor\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C89U6IRdktPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = 'https://drive.google.com/file/d/13GpeDjiVR1aRHpkAZc7EeH_cKf52q7qE/view?usp=sharing'\n",
        "test = 'https://drive.google.com/file/d/17JoUvCmpFXXFbgbZ9Ki3Xqh9qcl7UV8c/view?usp=sharing'\n",
        "submission = 'https://drive.google.com/file/d/1GN1lSsLU43kQaZtThc4dP60mz8ztwDsL/view?usp=sharing'\n",
        "dictionary = 'https://drive.google.com/file/d/1lAZnQFsBkPo8TNHYbq5mt2SpSMrG57WR/view?usp=sharing'\n",
        "\n",
        "\n",
        "# Creating a function to read a csv file shared via google\n",
        "#\n",
        "def read_csv(url):\n",
        "  url = 'https://drive.google.com/uc?export=download&id=' + url.split('/')[-2]\n",
        "  csv_raw = requests.get(url).text\n",
        "  csv = StringIO(csv_raw)\n",
        "  df = pd.read_csv(csv)\n",
        "  return df\n",
        "\n",
        "# Creating submission and training datataframes\n",
        "#\n",
        "sub = read_csv(submission)\n",
        "train = read_csv(train)\n",
        "test = read_csv(test)\n",
        "submission = read_csv(submission)\n",
        "dictionary = read_csv(dictionary)\n",
        "\n",
        "target = train.target\n",
        "\n",
        "# Aligning the training and testing datasets\n",
        "train, test = train.align(test, join = 'inner', axis = 1)\n",
        "\n",
        "train['separator'] = 0\n",
        "test['separator'] = 1\n",
        "\n",
        "comb = pd.concat([train, test])\n",
        "\n",
        "train = comb[comb.separator == 0]\n",
        "test = comb[comb.separator == 1]\n",
        "\n",
        "train.drop('separator', axis = 1, inplace = True)\n",
        "test.drop('separator', axis = 1, inplace = True)\n",
        "train['target'] = target\n",
        "\n",
        "final_blend_1 = pd.read_csv('final_blend_1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srptKPtI3pfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training models using different random states and the latest catboost\n",
        "#\n",
        "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
        "y = target\n",
        "\n",
        "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 29)\n",
        "\n",
        "predictions_cat_29 = CatBoostRegressor(logging_level='Silent').fit(X_train, y_train).predict(tes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KNf-sMf3pdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Same as before with the only difference being the random state\n",
        "# Using different random states will ensure that all the data hase been used in bulding the model\n",
        "#\n",
        "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
        "y = target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 65)\n",
        "\n",
        "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
        "\n",
        "estimators_1 = [\n",
        "    ('xgb', XGBRegressor(objective ='reg:squarederror')),\n",
        "    ('lr', LinearRegression()),\n",
        "    ('rf', RandomForestRegressor()),\n",
        "    ('lgb', LGBMRegressor()),\n",
        "    ('svr', SVR()),\n",
        "    ('lasso', Lasso()),\n",
        "    ('kneiba', KNeighborsRegressor()),\n",
        "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
        "]\n",
        "\n",
        "predictions_sreg_65 = StackingRegressor(estimators=estimators_1, final_estimator=CatBoostRegressor(logging_level='Silent')).fit(X_train, y_train).predict(tes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkuuEvQ63pb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train.drop(['ward', 'ADM4_PCODE', 'target'], axis = 1)\n",
        "y = target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 27)\n",
        "\n",
        "tes = test.drop(['ward', 'ADM4_PCODE'], axis = 1)\n",
        "\n",
        "estimators_1 = [\n",
        "    ('xgb', XGBRegressor(objective ='reg:squarederror')),\n",
        "    ('lr', LinearRegression()),\n",
        "    ('rf', RandomForestRegressor()),\n",
        "    ('lgb', LGBMRegressor()),\n",
        "    ('svr', SVR()),\n",
        "    ('lasso', Lasso()),\n",
        "    ('kneiba', KNeighborsRegressor()),\n",
        "    ('cat', CatBoostRegressor(logging_level='Silent'))\n",
        "]\n",
        "\n",
        "predictions_sreg_27 = StackingRegressor(estimators=estimators_1, final_estimator=CatBoostRegressor(logging_level='Silent')).fit(X_train, y_train).predict(tes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mf4Neos3pYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Further averaging, blending and retraining to generalise well\n",
        "#\n",
        "stack = [x*0.5 + y*0.5 for x, y in zip(predictions_sreg_65, predictions_sreg_27)]\n",
        "\n",
        "stack_2 = [x*0.5 + y*0.5 for x, y in zip(stack, predictions_cat_29)]\n",
        "\n",
        "\n",
        "X = tes.copy()\n",
        "y = stack_2\n",
        "\n",
        "ridge = Ridge()\n",
        "ridge.fit(X, y)\n",
        "preds_ridge = ridge.predict(X)\n",
        "\n",
        "cat = CatBoostRegressor(verbose = False)\n",
        "cat.fit(X, y)\n",
        "preds_cat = cat.predict(X)\n",
        "\n",
        "final_blend_2 = [x*0.5 +y*0.5 for x, y in zip(preds_ridge, preds_cat)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYWARbid3pVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making the final prediction\n",
        "#\n",
        "final_blend_3 = [x*0.5 + y*0.5 for x, y in zip(final_blend_1.target, final_blend_2)]\n",
        "sub_df = pd.DataFrame({'ward': test.ward, 'target': final_blend_3}) \n",
        "sub_df.to_csv('final_submission.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fgXhN_EGZJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}